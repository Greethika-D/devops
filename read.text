import gradio as gr
import ollama
from pypdf import PdfReader

def summarize_pdf(pdf):
    if pdf is None:
        return "upload a pdf"
    reader = PdfReader(pdf.name)
    text =""
    for page in reader.pages:
        text += page.extract_text() + "\n"

    prompt = f"Summarize the following pdf content clearly:\n\n{text}"

    response = ollama.chat(model = "qwen2.5:0.5b",messages = [{"role":"user","content":prompt}])
    return response["message"]["content"].strip()

gr.Interface(fn = summarize_pdf, inputs=gr.File(label="Upload PDF"),outputs = gr.Textbox(label="Summary", lines =12), 
             title="PDf summarizer",
             description="Upload pdf file").launch()




import gradio as gr
import ollama

with open("travel.csv", "r", encoding="utf-8") as f:
    travel_data = f.read()

prompt = f"""
You are a helpful AI travel assistant.
Answer questions based only on the data below.
If the answer is not in this data, say "I'm sorry, I don't have that information."

{travel_data}
"""

def trav_agent(user_input):
    response = ollama.chat(
        model="qwen2.5:0.5b",
        messages=[
            {'role': 'system', 'content': prompt},
            {'role': 'user', 'content': user_input}
        ]
    )
    answer = response['message']['content'].strip()

    if "I'm sorry, I don't have that information." in answer:
        response = ollama.chat(
            model="qwen2.5:0.5b",
            messages=[{'role': 'user', 'content': user_input}]
        )
        answer = response['message']['content'].strip()

    return answer

demo = gr.Interface(
    fn=trav_agent,
    inputs=gr.Textbox(label="Ask your travel question"),
    outputs=gr.Textbox(label="Answer", lines=8),
    title="AI Travel Assistant",
    description="Answers using data from travel.csv. Falls back to Qwen if not found."
).launch()




import gradio as gr
import ollama
import pandas as pd

def summarize_news(csv_file):
    if csv_file is None:
        return "Please upload a CSV file.", pd.DataFrame()

    df = pd.read_csv(csv_file.name)

    text_col = "article"

    summaries = []

    for idx, article in enumerate(df[text_col]):
        prompt = f"""
Summarize the news article below into:
1. A short headline
2. A 2-3 sentence summary
3. Three key bullet points

Article:
{article}
"""

        response = ollama.chat(
            model="qwen2.5:0.5b",
            messages=[{"role": "user", "content": prompt}]
        )

        summaries.append({
            "Article #": idx + 1,
            "Summary": response["message"]["content"].strip()
        })

    result_df = pd.DataFrame(summaries)
    return "Done", result_df


demo = gr.Interface(
    fn=summarize_news,
    inputs=gr.File(label="Upload CSV (must contain 'article' column)"),
    outputs=[gr.Textbox(label="Status"), gr.Dataframe(label="Summaries")],
    title="News Summarization Dashboard",
    description="Summarizes each news article into headline, summary, and key points."
).launch()




import gradio as gr
import pandas as pd
import ollama

def blog_writer(csv_file, topic):
    if csv_file is not None and (topic is None or topic == ""):
        path = csv_file.name if hasattr(csv_file, "name") else csv_file
        df = pd.read_csv(path)
        choices = df["topic"].dropna().astype(str).tolist()
        return gr.update(choices=choices), ""

    if not topic:
        return gr.update(), "Please upload a CSV and select a topic."

    prompt = f"Write a detailed, easy-to-read blog post on: {topic}"
    response = ollama.chat(
        model="qwen2.5:0.5b",
        messages=[{"role": "user", "content": prompt}]
    )
    return gr.update(), response["message"]["content"].strip()


demo = gr.Interface(
    fn=blog_writer,
    inputs=[gr.File(label="Upload Topics CSV (column: topic)"), gr.Dropdown(label="Select Topic")],
    outputs=[gr.Dropdown(), gr.Textbox(label="Generated Blog", lines=12)],
    title="Minimal AI Blog Writer",
    description="Upload topics → select one → generate blog"
).launch()




import gradio as gr
import ollama

def generate_blog(topic):
    prompt = f"Write a detailed, engaging blog post about '{topic}'. Include an introduction, body, and conclusion."
    resp = ollama.chat(model="qwen2.5:0.5b", messages=[{"role": "user", "content": prompt}])
    return resp["message"]["content"]

gr.Interface(
    fn=generate_blog,
    inputs=gr.Textbox(label="Enter Blog Topic"),
    outputs=gr.Textbox(label="Generated Blog Content", lines=12),
    title="AI-Powered Blog Content Generator",
    description="Generate professional blog articles with Qwen 2.5."
).launch()




import requests

faq_data = [
{"question": "", "answer": ""},
{"question": "", "answer": ""},
{"question": "", "answer": ""},
{"question": "", "answer": ""},
{"question": "", "answer": ""}
]

def ask_ollama(prompt, model="qwen2.5:0.5b"):
    url = "http://localhost:11434/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    response = requests.post(url, json=payload)
    return response.json()['response']

def faq_chatbot(user_question):
    prompt = ("You are a helpful customer support chatbot for an e-commerce website.\n"
              "You will be given a list of FAQs. Answer the user question using the most relevant FAQ.\n"
            "If the question doesn't match any FAQ, politely say you don't know and offer general help.\n\n"
            "Here are the FAQs:\n")
    for item in faq_data:
        prompt += f"Q: {item['question']}\nA: {item['answer']}\n\n"
    
    prompt += f"User question: {user_question}\nChatbot Answer:"
    answer = ask_ollama(prompt)
    return answer

while True:
    prompt = input("Enter your Query: ")
    if prompt == "exit":
        print("Bye.")
        break
    print(faq_chatbot(prompt))
